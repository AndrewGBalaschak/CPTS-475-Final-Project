{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\anaconda3\\envs\\torch4\\Lib\\site-packages\\_ctgan\\synthesizer.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tabgan.sampler import GANGenerator\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1.losses import mean_squared_error as old_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Identify non-numeric columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['number', 'bool']).columns\n",
    "\n",
    "    # Label Encode categorical columns\n",
    "    le = LabelEncoder()\n",
    "    df[non_numeric_cols] = df[non_numeric_cols].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "    # Convert non-numeric columns back to integers\n",
    "    df[non_numeric_cols] = df[non_numeric_cols].astype(int)\n",
    "\n",
    "    # Convert boolean columns directly to integers\n",
    "    bool_cols = df.select_dtypes(include='bool').columns\n",
    "    df[bool_cols] = df[bool_cols].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'L4_SRC_PORT', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'OUT_BYTES', 'IN_PKTS', 'OUT_PKTS', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS', 'Label', 'Attack', 'Dataset', 'sIP31', 'sIP30', 'sIP29', 'sIP28', 'sIP27', 'sIP26', 'sIP25', 'sIP24', 'sIP23', 'sIP22', 'sIP21', 'sIP20', 'sIP19', 'sIP18', 'sIP17', 'sIP16', 'sIP15', 'sIP14', 'sIP13', 'sIP12', 'sIP11', 'sIP10', 'sIP9', 'sIP8', 'sIP7', 'sIP6', 'sIP5', 'sIP4', 'sIP3', 'sIP2', 'sIP1', 'sIP0', 'dIP31', 'dIP30', 'dIP29', 'dIP28', 'dIP27', 'dIP26', 'dIP25', 'dIP24', 'dIP23', 'dIP22', 'dIP21', 'dIP20', 'dIP19', 'dIP18', 'dIP17', 'dIP16', 'dIP15', 'dIP14', 'dIP13', 'dIP12', 'dIP11', 'dIP10', 'dIP9', 'dIP8', 'dIP7', 'dIP6', 'dIP5', 'dIP4', 'dIP3', 'dIP2', 'dIP1', 'dIP0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your dataset\n",
    "dataset_path = \"data/cleaned/NF-UQ-NIDS-ATTACKS\"\n",
    "target_column = \"Label\"  # Replace with your target column name\n",
    "\n",
    "df_pre = pd.read_csv(dataset_path, nrows=10000)\n",
    "df = preprocess_data(df_pre)\n",
    "\n",
    "# Specify the columns to be used\n",
    "COLS_USED = list(df.columns)\n",
    "COlS_TRAIN = list(df.columns).remove(target_column)\n",
    "\n",
    "\n",
    "df = df[COLS_USED]\n",
    "print(COLS_USED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  L4_SRC_PORT  L4_DST_PORT  PROTOCOL  L7_PROTO  IN_BYTES  \\\n",
      "0          29        43025           25         6       3.0     41290   \n",
      "1          40        64923           80         6       7.0       994   \n",
      "2          67         9022          111         6      11.0       552   \n",
      "3          93         1752           25         6       3.0      3022   \n",
      "4         115        53967          111        17      11.0       168   \n",
      "\n",
      "   OUT_BYTES  IN_PKTS  OUT_PKTS  TCP_FLAGS  FLOW_DURATION_MILLISECONDS  Label  \\\n",
      "0       2080       48        24         27                         803      1   \n",
      "1        256       10         6         19                         189      1   \n",
      "2        336       10         8         19                         678      1   \n",
      "3       1636       20        20         19                         789      1   \n",
      "4          0        2         0          0                           0      1   \n",
      "\n",
      "   Attack  Dataset  sIP31  sIP30  sIP29  sIP28  sIP27  sIP26  sIP25  sIP24  \\\n",
      "0       6        3      1      0      1      0      1      1      1      1   \n",
      "1       6        3      1      0      1      0      1      1      1      1   \n",
      "2      10        3      1      0      1      0      1      1      1      1   \n",
      "3       5        3      1      0      1      0      1      1      1      1   \n",
      "4      10        3      1      0      1      0      1      1      1      1   \n",
      "\n",
      "   sIP23  sIP22  sIP21  sIP20  sIP19  sIP18  sIP17  sIP16  sIP15  sIP14  \\\n",
      "0      0      0      1      0      1      1      0      1      1      0   \n",
      "1      0      0      1      0      1      1      0      1      1      0   \n",
      "2      0      0      1      0      1      1      0      1      1      0   \n",
      "3      0      0      1      0      1      1      0      1      1      0   \n",
      "4      0      0      1      0      1      1      0      1      1      0   \n",
      "\n",
      "   sIP13  sIP12  sIP11  sIP10  sIP9  sIP8  sIP7  sIP6  sIP5  sIP4  sIP3  sIP2  \\\n",
      "0      1      1      0      0     0     0     0     0     0     0     0     0   \n",
      "1      1      1      0      0     0     0     0     0     0     0     0     0   \n",
      "2      1      1      0      0     0     0     0     0     0     0     0     0   \n",
      "3      1      1      0      0     0     0     0     0     0     0     0     0   \n",
      "4      1      1      0      0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   sIP1  sIP0  dIP31  dIP30  dIP29  dIP28  dIP27  dIP26  dIP25  dIP24  dIP23  \\\n",
      "0     0     1      1      0      0      1      0      1      0      1      1   \n",
      "1     1     1      1      0      0      1      0      1      0      1      1   \n",
      "2     1     1      1      0      0      1      0      1      0      1      1   \n",
      "3     1     1      1      0      0      1      0      1      0      1      1   \n",
      "4     1     1      1      0      0      1      0      1      0      1      1   \n",
      "\n",
      "   dIP22  dIP21  dIP20  dIP19  dIP18  dIP17  dIP16  dIP15  dIP14  dIP13  \\\n",
      "0      0      1      0      1      0      1      1      0      1      1   \n",
      "1      0      1      0      1      0      1      1      0      1      1   \n",
      "2      0      1      0      1      0      1      1      0      1      1   \n",
      "3      0      1      0      1      0      1      1      0      1      1   \n",
      "4      0      1      0      1      0      1      1      0      1      1   \n",
      "\n",
      "   dIP12  dIP11  dIP10  dIP9  dIP8  dIP7  dIP6  dIP5  dIP4  dIP3  dIP2  dIP1  \\\n",
      "0      1      1      1     1     0     0     0     0     1     0     0     0   \n",
      "1      1      1      1     1     0     0     0     0     1     0     0     0   \n",
      "2      1      1      1     1     0     0     0     0     0     1     1     0   \n",
      "3      1      1      1     1     0     0     0     0     0     1     0     1   \n",
      "4      1      1      1     1     0     0     0     0     0     1     1     1   \n",
      "\n",
      "   dIP0  \n",
      "0     0  \n",
      "1     1  \n",
      "2     1  \n",
      "3     0  \n",
      "4     0  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and test sets\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(\n",
    "    df.drop(target_column, axis=1),\n",
    "    df[target_column],\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dataframe versions for tabular GAN\n",
    "df_x_test, df_y_test = df_x_test.reset_index(drop=True), df_y_test.reset_index(drop=True)\n",
    "df_y_train = pd.DataFrame(df_y_train)\n",
    "df_y_test = pd.DataFrame(df_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_x_train.values\n",
    "x_test = df_x_test.values\n",
    "y_train = df_y_train.values\n",
    "y_test = df_y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.0, 64923.0, 80.0, 6.0, 7.0, 994.0, 256.0, 10.0, 6.0, 19.0, 189.0, 1.0, 6.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "second_row_list = df.iloc[1].tolist()\n",
    "print(second_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "69672/69672 - 81s - loss: 0.0000e+00 - val_loss: 0.0000e+00 - 81s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "69672/69672 - 86s - loss: 0.0000e+00 - val_loss: 0.0000e+00 - 86s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "69672/69672 - 77s - loss: 0.0000e+00 - val_loss: 0.0000e+00 - 77s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "69672/69672 - 75s - loss: 0.0000e+00 - val_loss: 0.0000e+00 - 75s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "69672/69672 - 76s - loss: 0.0000e+00 - val_loss: 0.0000e+00 - 76s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "69672/69672 - 78s - loss: 0.0000e+00 - val_loss: 0.0000e+00 - 78s/epoch - 1ms/step\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x281055cf590>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
    "                        patience=5, verbose=1, mode='auto',\n",
    "                        restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
    "          callbacks=[monitor], verbose=2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SampleData.generate_data_pipe() got an unexpected keyword argument 'gen_x_times'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shrey\\OneDrive\\Desktop\\475fin\\CPTS-475-Final-Project\\tgan3.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shrey/OneDrive/Desktop/475fin/CPTS-475-Final-Project/tgan3.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gen_x, gen_y \u001b[39m=\u001b[39m GANGenerator()\u001b[39m.\u001b[39;49mgenerate_data_pipe(df_x_train, df_y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shrey/OneDrive/Desktop/475fin/CPTS-475-Final-Project/tgan3.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                   df_x_test, deep_copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shrey/OneDrive/Desktop/475fin/CPTS-475-Final-Project/tgan3.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                   only_adversarial\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shrey/OneDrive/Desktop/475fin/CPTS-475-Final-Project/tgan3.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                   use_adversarial\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shrey/OneDrive/Desktop/475fin/CPTS-475-Final-Project/tgan3.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                                   gen_x_times \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: SampleData.generate_data_pipe() got an unexpected keyword argument 'gen_x_times'"
     ]
    }
   ],
   "source": [
    "gen_x, gen_y = GANGenerator().generate_data_pipe(df_x_train, df_y_train,\n",
    "                                                  df_x_test, deep_copy=True,\n",
    "                                                  only_adversarial=False,\n",
    "                                                  use_adversarial=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
